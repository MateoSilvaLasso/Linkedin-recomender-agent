# üîç LinkedIn Data Science Job Scraper

Este repositorio contiene **dos versiones** de un proyecto que realiza scraping en **LinkedIn** para extraer ofertas de empleo en el campo de **Data Science**, con capacidades de recomendaci√≥n basadas en modelos de lenguaje (LLMs).

---

## üìÅ Estructura del Proyecto

```
.
‚îú‚îÄ‚îÄ dummy_solution/       ‚Üí Versi√≥n b√°sica del proyecto (Streamlit + PostgreSQL)
‚îú‚îÄ‚îÄ rag_solution/    ‚Üí Versi√≥n robusta con RAG, MongoDB, embeddings y Streamlit
‚îú‚îÄ‚îÄ requirements.txt
|‚îÄ‚îÄ .env
‚îî‚îÄ‚îÄ README.md
```

---

## üß™ Versi√≥n 1 ‚Äî Dummy (`v1_dummy/`)

Una versi√≥n inicial y funcional que:
- Realiza scraping con **Selenium**
- Almacena los datos en **PostgreSQL (Supabase)**
- Utiliza **Gemini 2.0 API** para generar recomendaciones
- Manda el **texto completo** de las ofertas como contexto en cada prompt

> ‚ùó Esto puede ser **costoso y poco eficiente** en uso de tokens, especialmente si se quiere escalar o trabajar con muchos datos.

---

## üöÄ Versi√≥n 2 ‚Äî Avanzada con RAG (`v2_advanced/`)

Una soluci√≥n m√°s potente y optimizada que:
- Realiza scraping con **Selenium**
- Almacena los datos estructurados en **MongoDB**
- Genera **embeddings sem√°nticos** de cada oferta
- Utiliza **RAG (Retrieval-Augmented Generation)** para enviar al LLM solo la informaci√≥n m√°s relevante, no todo el corpus
- Escala mucho mejor en volumen y complejidad de consultas

---

## ‚öñÔ∏è Comparaci√≥n: Dummy vs RAG

| Caracter√≠stica                    | Dummy (`v1_dummy`)                            | RAG (`v2_advanced`)                             |
|----------------------------------|-----------------------------------------------|-------------------------------------------------|
| Modelo de recuperaci√≥n           | Prompt completo                                | B√∫squeda sem√°ntica con embeddings               |
| Costo por token                  | Alto (todo el texto va al LLM)                | Bajo (solo se manda lo relevante)              |
| Escalabilidad                    | Limitada                                       | Alta, por separaci√≥n de almacenamiento y consulta |
| Precisi√≥n en recomendaciones     | Gen√©rica (basada en texto bruto)              | Contextual (basada en similitud sem√°ntica)      |
| Almacenamiento                   | Relacional (PostgreSQL)                        | NoSQL + vectores (MongoDB + vector store)       |
| Ideal para                       | Prototipado r√°pido                             | Producci√≥n o sistemas m√°s robustos              |

> ‚úÖ **Ventaja clave de la versi√≥n con RAG**:  
> **Reduce el uso de tokens**, lo que disminuye los costos por consulta y mejora la calidad de las respuestas al enfocarse solo en la informaci√≥n relevante.

---

## üõ† Tecnolog√≠as Utilizadas

- **Selenium**
- **Streamlit**
- **LlamaIndex**
- **Gemini 2.0 API**
- **PostgreSQL (v1) / MongoDB + vector store (v2)**

---

## Instalaci√≥n

### 1. Clonar el repositorio
```bash
git clone https://github.com/tu-usuario/tu-repositorio.git
cd tu-repositorio
```


### 2. Crear y activar un entorno virtual
```bash
python -m venv venv
source venv/bin/activate  # En Linux/macOS
venv\Scripts\activate    # En Windows
```


### 3. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 4. Configurar credenciales
Crea un archivo .env en la ra√≠z del proyecto con las credenciales necesarias:
```env
GOOGLE_API_KEY = api key of your agent
#The next three options are used if you need to be your own web scraping, the scheme that i used is this CREATE TABLE ofertas_linkedin (id UUID PRIMARY KEY DEFAULT gen_random_uuid(), titulo TEXT NOT NULL #descripcion JSONB NOT NULL,categoria TEXT NOT NULL);
SUPABASE_URL = url of your data base
SUPABASE_KEY = key of of you data base
MY_PASSWORD = your linkedin password
COMPLETED_PASSWORD = your completed uri(with password, mongo)
DB_URI = the uri of your data base(postgress)
```

## üß™ ¬øC√≥mo probar cada versi√≥n?

### Versi√≥n Dummy
```bash
cd dummy_solution
streamlit run app.py
```

### Versi√≥n Avanzada (RAG)
```bash
cd rag_solution
python scraper.py       # Extrae ofertas, caso que no los tengas
streamlit run app.py  
```

para esta solucion ya los embeddings estan generados y almacenados, si quieres conocer como esta hecho, no dudes en contactarme.

---

## ü§ù Contribuci√≥n

¬°Eres bienvenido a contribuir! Explora cualquiera de las dos versiones, sugiere mejoras o prop√≥n nuevas funcionalidades.

---

üí° *Desarrollado por Mateo Silva ‚Äî Explorando c√≥mo los LLMs y el RAG pueden potenciar soluciones inteligentes y eficientes para la b√∫squeda de empleo en Data Science.*
